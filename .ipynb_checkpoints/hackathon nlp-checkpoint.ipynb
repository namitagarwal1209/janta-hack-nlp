{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,VotingClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "game_overview = pd.read_csv('game_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 5)\n",
      "(8045, 4)\n",
      "(64, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(game_overview.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
       "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
       "1  Best game, more better than Sam Pepper's YouTu...                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>Lag Studios</td>\n",
       "      <td>Lag Studios</td>\n",
       "      <td>['Horror', 'Free to Play', 'Cute', 'First-Pers...</td>\n",
       "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sakura Clicker</td>\n",
       "      <td>Winged Cloud</td>\n",
       "      <td>Winged Cloud</td>\n",
       "      <td>['Nudity', 'Anime', 'Free to Play', 'Mature', ...</td>\n",
       "      <td>The latest entry in the Sakura series is more ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title      developer      publisher  \\\n",
       "0  Spooky's Jump Scare Mansion   Lag Studios    Lag Studios    \n",
       "1               Sakura Clicker  Winged Cloud   Winged Cloud    \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Horror', 'Free to Play', 'Cute', 'First-Pers...   \n",
       "1  ['Nudity', 'Anime', 'Free to Play', 'Mature', ...   \n",
       "\n",
       "                                            overview  \n",
       "0  Can you survive 1000 rooms of cute terror? Or ...  \n",
       "1  The latest entry in the Sakura series is more ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_overview.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1603</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Nice graphics, new maps, weapons and models. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>I would not recommend getting into this at its...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                             title    year  \\\n",
       "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
       "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
       "\n",
       "                                         user_review  \n",
       "0  Nice graphics, new maps, weapons and models. B...  \n",
       "1  I would not recommend getting into this at its...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting year from float to string\n",
    "#filling nan values and 2014(by chance)\n",
    "\n",
    "train['year'] = train['year'].fillna(2014.0).astype(int).astype(str)\n",
    "test['year'] = test['year'].fillna(2014.0).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title'].nunique(), test['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 common titles between train and test dataset\n"
     ]
    }
   ],
   "source": [
    "#checking out number of common games in train and test list\n",
    "\n",
    "game_tr = train['title'].unique().tolist()\n",
    "game_te = test['title'].unique().tolist()\n",
    "\n",
    "common = [game for game in game_te if game in game_tr]\n",
    "print(\"there are {} common titles between train and test dataset\".format(len(common)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing developer, publisher and title of game_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = [e.strip().replace(',','').replace('.','').replace('-','_').replace(' ','_').lower() for e in game_overview['developer'].values]\n",
    "pub = [e.strip().replace(',','').replace('.','').replace('-','_').replace(' ','_').lower() for e in game_overview['publisher'].values]\n",
    "\n",
    "game_overview.drop(['developer','publisher'], axis=1, inplace=True)\n",
    "\n",
    "game_overview[['developer']] = pd.DataFrame(dev)\n",
    "game_overview[['publisher']] = pd.DataFrame(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_title(data):\n",
    "    preprocessed_title=[]\n",
    "    for row in data:\n",
    "        row = re.sub(r\"\\'s\", \" is\", row)\n",
    "        row = re.sub('[^A-Za-z0-9]+', ' ', row)\n",
    "        row = row.replace('&','')\n",
    "        row = row.replace(',','') \n",
    "        row = row.replace(' ','_')\n",
    "        row = row.replace('-','_')\n",
    "        row = row.replace('!','_')\n",
    "\n",
    "        preprocessed_title.append(row.lower().strip())\n",
    "        \n",
    "    return preprocessed_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['preprocessed_title'] = preprocess_title(train['title'].values)\n",
    "test['preprocessed_title'] = preprocess_title(test['title'].values)\n",
    "game_overview['preprocessed_title'] = preprocess_title(game_overview['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['title'], axis=1, inplace=True)\n",
    "test.drop(['title'], axis=1, inplace=True)\n",
    "game_overview.drop(['title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>overview</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>preprocessed_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['Horror', 'Free to Play', 'Cute', 'First-Pers...</td>\n",
       "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['Nudity', 'Anime', 'Free to Play', 'Mature', ...</td>\n",
       "      <td>The latest entry in the Sakura series is more ...</td>\n",
       "      <td>winged_cloud</td>\n",
       "      <td>winged_cloud</td>\n",
       "      <td>sakura_clicker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  ['Horror', 'Free to Play', 'Cute', 'First-Pers...   \n",
       "1  ['Nudity', 'Anime', 'Free to Play', 'Mature', ...   \n",
       "\n",
       "                                            overview     developer  \\\n",
       "0  Can you survive 1000 rooms of cute terror? Or ...   lag_studios   \n",
       "1  The latest entry in the Sakura series is more ...  winged_cloud   \n",
       "\n",
       "      publisher            preprocessed_title  \n",
       "0   lag_studios  spooky_is_jump_scare_mansion  \n",
       "1  winged_cloud                sakura_clicker  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_overview.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Handling tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Horror', 'Free to Play', 'Cute', 'First-Person', 'Singleplayer', 'Psychological Horror', 'Indie', 'Adventure', 'Dark', 'Funny', 'Atmospheric', 'Action', 'Walking Simulator', 'Survival', 'Survival Horror', 'Anime', 'Gore', 'Comedy', 'Multiplayer', 'Illuminati']\n",
      "['Nudity', 'Anime', 'Free to Play', 'Mature', 'Sexual Content', 'Clicker', 'Female Protagonist', 'Singleplayer', 'Casual', 'Indie', 'Fantasy', 'NSFW', 'Memes', 'Funny', '2D', 'RPG', 'Story Rich', 'Adventure', 'Dating Sim', 'Illuminati']\n"
     ]
    }
   ],
   "source": [
    "print(game_overview['tags'][0])\n",
    "print(game_overview['tags'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting list from the string\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "game_overview['tags'] = game_overview['tags'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_overview['tags'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of tags: 161\n"
     ]
    }
   ],
   "source": [
    "#extracting all tags \n",
    "final=[]\n",
    "for l in game_overview['tags']:\n",
    "    final.extend(l)\n",
    "tags = list(set(final))\n",
    "print(\"no of tags:\",len(tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for row in game_overview['tags']:\n",
    "    b=np.zeros(len(tags))\n",
    "    for ele in row:\n",
    "        b[tags.index(ele)] =1 \n",
    "    l.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(l, columns=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team-Based</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Local Co-Op</th>\n",
       "      <th>Turn-Based Strategy</th>\n",
       "      <th>MMORPG</th>\n",
       "      <th>Fast-Paced</th>\n",
       "      <th>City Builder</th>\n",
       "      <th>Dungeons &amp; Dragons</th>\n",
       "      <th>Sandbox</th>\n",
       "      <th>Mod</th>\n",
       "      <th>...</th>\n",
       "      <th>Family Friendly</th>\n",
       "      <th>Exploration</th>\n",
       "      <th>Zombies</th>\n",
       "      <th>Dating Sim</th>\n",
       "      <th>Multiplayer</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Masterpiece</th>\n",
       "      <th>Dragons</th>\n",
       "      <th>2D Fighter</th>\n",
       "      <th>NSFW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team-Based  Sports  Local Co-Op  Turn-Based Strategy  MMORPG  Fast-Paced  \\\n",
       "0         0.0     0.0          0.0                  0.0     0.0         0.0   \n",
       "1         0.0     0.0          0.0                  0.0     0.0         0.0   \n",
       "\n",
       "   City Builder  Dungeons & Dragons  Sandbox  Mod  ...  Family Friendly  \\\n",
       "0           0.0                 0.0      0.0  0.0  ...              0.0   \n",
       "1           0.0                 0.0      0.0  0.0  ...              0.0   \n",
       "\n",
       "   Exploration  Zombies  Dating Sim  Multiplayer  Flight  Masterpiece  \\\n",
       "0          0.0      0.0         0.0          1.0     0.0          0.0   \n",
       "1          0.0      0.0         1.0          0.0     0.0          0.0   \n",
       "\n",
       "   Dragons  2D Fighter  NSFW  \n",
       "0      0.0         0.0   0.0  \n",
       "1      0.0         0.0   1.0  \n",
       "\n",
       "[2 rows x 161 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 5)\n",
      "(64, 161)\n"
     ]
    }
   ],
   "source": [
    "print(game_overview.shape)\n",
    "print(tags_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_overview = pd.concat([game_overview,tags_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_overview['no_of_tags'] = game_overview['tags'].apply(len).tolist()\n",
    "game_overview.drop('tags', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>Team-Based</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Local Co-Op</th>\n",
       "      <th>Turn-Based Strategy</th>\n",
       "      <th>MMORPG</th>\n",
       "      <th>Fast-Paced</th>\n",
       "      <th>...</th>\n",
       "      <th>Exploration</th>\n",
       "      <th>Zombies</th>\n",
       "      <th>Dating Sim</th>\n",
       "      <th>Multiplayer</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Masterpiece</th>\n",
       "      <th>Dragons</th>\n",
       "      <th>2D Fighter</th>\n",
       "      <th>NSFW</th>\n",
       "      <th>no_of_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The latest entry in the Sakura series is more ...</td>\n",
       "      <td>winged_cloud</td>\n",
       "      <td>winged_cloud</td>\n",
       "      <td>sakura_clicker</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview     developer  \\\n",
       "0  Can you survive 1000 rooms of cute terror? Or ...   lag_studios   \n",
       "1  The latest entry in the Sakura series is more ...  winged_cloud   \n",
       "\n",
       "      publisher            preprocessed_title  Team-Based  Sports  \\\n",
       "0   lag_studios  spooky_is_jump_scare_mansion         0.0     0.0   \n",
       "1  winged_cloud                sakura_clicker         0.0     0.0   \n",
       "\n",
       "   Local Co-Op  Turn-Based Strategy  MMORPG  Fast-Paced  ...  Exploration  \\\n",
       "0          0.0                  0.0     0.0         0.0  ...          0.0   \n",
       "1          0.0                  0.0     0.0         0.0  ...          0.0   \n",
       "\n",
       "   Zombies  Dating Sim  Multiplayer  Flight  Masterpiece  Dragons  2D Fighter  \\\n",
       "0      0.0         0.0          1.0     0.0          0.0      0.0         0.0   \n",
       "1      0.0         1.0          0.0     0.0          0.0      0.0         0.0   \n",
       "\n",
       "   NSFW  no_of_tags  \n",
       "0   0.0          20  \n",
       "1   1.0          20  \n",
       "\n",
       "[2 rows x 166 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_overview.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "      <th>preprocessed_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  year                                        user_review  \\\n",
       "0          1  2016  I'm scared and hearing creepy voices.  So I'll...   \n",
       "1          2  2016  Best game, more better than Sam Pepper's YouTu...   \n",
       "\n",
       "   user_suggestion            preprocessed_title  \n",
       "0                1  spooky_is_jump_scare_mansion  \n",
       "1                1  spooky_is_jump_scare_mansion  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 170)\n",
      "(8045, 169)\n"
     ]
    }
   ],
   "source": [
    "data_tr = train.merge(game_overview, on ='preprocessed_title')\n",
    "data_te = test.merge(game_overview, on ='preprocessed_title')\n",
    "print(data_tr.shape)\n",
    "print(data_te.shape)\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:12<00:00, 1374.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data_tr['user_review'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sent.lower().strip())\n",
    "\n",
    "data_tr['preprocessed_reviews'] = preprocessed_reviews\n",
    "data_tr.drop(['user_review'],axis=1,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:18<00:00, 968.39it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_overview = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data_tr['overview'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ') \n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "    preprocessed_overview.append(sent.lower().strip())\n",
    "    \n",
    "    \n",
    "data_tr['preprocessed_overview'] = preprocessed_overview\n",
    "data_tr.drop(['overview'],axis=1,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding #words in preprocessed_reviews\n",
    "l=[]\n",
    "for sent in preprocessed_reviews:\n",
    "    count=0\n",
    "    for word in sent:\n",
    "        count+=1\n",
    "    l.append(count)\n",
    "    \n",
    "data_tr[['#words_in_review']] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding #words in preprocessed_overviews\n",
    "l=[]\n",
    "for sent in preprocessed_overview:\n",
    "    count=0\n",
    "    for word in sent:\n",
    "        count+=1\n",
    "    l.append(count)\n",
    "    \n",
    "data_tr[['#words_in_overview']] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:03<00:00, 2349.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data_te['user_review'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sent.lower().strip())\n",
    "\n",
    "data_te['preprocessed_reviews'] = preprocessed_reviews\n",
    "data_te.drop(['user_review'],axis=1,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:06<00:00, 1296.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_overview = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data_te['overview'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ') \n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "    preprocessed_overview.append(sent.lower().strip())\n",
    "    \n",
    "    \n",
    "data_te['preprocessed_overview'] = preprocessed_overview\n",
    "data_te.drop(['overview'],axis=1,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding #words in preprocessed_reviews\n",
    "l=[]\n",
    "for sent in preprocessed_reviews:\n",
    "    count=0\n",
    "    for word in sent:\n",
    "        count+=1\n",
    "    l.append(count)\n",
    "    \n",
    "data_te[['#words_in_review']] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding #words in preprocessed_overviews\n",
    "l=[]\n",
    "for sent in preprocessed_overview:\n",
    "    count=0\n",
    "    for word in sent:\n",
    "        count+=1\n",
    "    l.append(count)\n",
    "    \n",
    "data_te[['#words_in_overview']] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/namitagarwal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:22<00:00, 770.07it/s] \n"
     ]
    }
   ],
   "source": [
    "#citation: https://www.programcreek.com/python/example/100005/nltk.sentiment.vader.SentimentIntensityAnalyzer\n",
    "\n",
    "sentiments=[]\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for review in tqdm(data_tr['preprocessed_reviews']):\n",
    "    sentiment = sid.polarity_scores(review)\n",
    "        \n",
    "    for k in sorted(sentiment):\n",
    "        sentiments.append([sentiment['neg'], sentiment['pos'],\n",
    "                           sentiment['neu'], sentiment['compound']]) \n",
    "        \n",
    "data_tr[['neg', 'pos', 'neu', 'compound']] = pd.DataFrame(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:10<00:00, 773.91it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiments=[]\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for review in tqdm(data_te['preprocessed_reviews']):\n",
    "    sentiment = sid.polarity_scores(review)\n",
    "        \n",
    "    for k in sorted(sentiment):\n",
    "        sentiments.append([sentiment['neg'], sentiment['pos'],\n",
    "                           sentiment['neu'], sentiment['compound']]) \n",
    "        \n",
    "data_te[['neg', 'pos', 'neu', 'compound']] = pd.DataFrame(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>year</th>\n",
       "      <th>user_suggestion</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Team-Based</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Local Co-Op</th>\n",
       "      <th>Turn-Based Strategy</th>\n",
       "      <th>...</th>\n",
       "      <th>NSFW</th>\n",
       "      <th>no_of_tags</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>preprocessed_overview</th>\n",
       "      <th>#words_in_review</th>\n",
       "      <th>#words_in_overview</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>scared hearing creepy voices pause moment writ...</td>\n",
       "      <td>survive 1000 rooms cute terror break cuteness ...</td>\n",
       "      <td>428</td>\n",
       "      <td>251</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>best game better sam pepper youtube account 10...</td>\n",
       "      <td>survive 1000 rooms cute terror break cuteness ...</td>\n",
       "      <td>242</td>\n",
       "      <td>251</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.2516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  year  user_suggestion            preprocessed_title  \\\n",
       "0          1  2016                1  spooky_is_jump_scare_mansion   \n",
       "1          2  2016                1  spooky_is_jump_scare_mansion   \n",
       "\n",
       "     developer    publisher  Team-Based  Sports  Local Co-Op  \\\n",
       "0  lag_studios  lag_studios         0.0     0.0          0.0   \n",
       "1  lag_studios  lag_studios         0.0     0.0          0.0   \n",
       "\n",
       "   Turn-Based Strategy  ...  NSFW  no_of_tags  \\\n",
       "0                  0.0  ...   0.0          20   \n",
       "1                  0.0  ...   0.0          20   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  scared hearing creepy voices pause moment writ...   \n",
       "1  best game better sam pepper youtube account 10...   \n",
       "\n",
       "                               preprocessed_overview  #words_in_review  \\\n",
       "0  survive 1000 rooms cute terror break cuteness ...               428   \n",
       "1  survive 1000 rooms cute terror break cuteness ...               242   \n",
       "\n",
       "   #words_in_overview    neg    pos    neu  compound  \n",
       "0                 251  0.173  0.196  0.631    0.2516  \n",
       "1                 251  0.173  0.196  0.631    0.2516  \n",
       "\n",
       "[2 rows x 176 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 176)\n",
      "(8045, 175)\n"
     ]
    }
   ],
   "source": [
    "print(data_tr.shape)\n",
    "print(data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding Numerical\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#neg\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['neg'].values.reshape(1,-1))\n",
    "\n",
    "neg_train = scalar.transform(data_tr['neg'].values.reshape(1,-1)).reshape(-1,1)\n",
    "neg_test = scalar.transform(data_te['neg'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(neg_train.shape)\n",
    "print(neg_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#pos\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['pos'].values.reshape(1,-1))\n",
    "\n",
    "pos_train = scalar.transform(data_tr['pos'].values.reshape(1,-1)).reshape(-1,1)\n",
    "pos_test = scalar.transform(data_te['pos'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(pos_train.shape)\n",
    "print(pos_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#neu\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['neu'].values.reshape(1,-1))\n",
    "\n",
    "neu_train = scalar.transform(data_tr['neu'].values.reshape(1,-1)).reshape(-1,1)\n",
    "neu_test = scalar.transform(data_te['neu'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(neu_train.shape)\n",
    "print(neu_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#compound \n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['compound'].values.reshape(1,-1))\n",
    "\n",
    "compound_train = scalar.transform(data_tr['compound'].values.reshape(1,-1)).reshape(-1,1)\n",
    "compound_test = scalar.transform(data_te['compound'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(compound_train.shape)\n",
    "print(compound_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#no_of_tags\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['no_of_tags'].values.reshape(1,-1))\n",
    "\n",
    "no_of_tags_train = scalar.transform(data_tr['no_of_tags'].values.reshape(1,-1)).reshape(-1,1)\n",
    "no_of_tags_test = scalar.transform(data_te['no_of_tags'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(no_of_tags_train.shape)\n",
    "print(no_of_tags_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#words_in_review\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['#words_in_review'].values.reshape(1,-1))\n",
    "\n",
    "words_in_review_train = scalar.transform(data_tr['#words_in_review'].values.reshape(1,-1)).reshape(-1,1)\n",
    "words_in_review_test = scalar.transform(data_te['#words_in_review'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(words_in_review_train.shape)\n",
    "print(words_in_review_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 1)\n",
      "(8045, 1)\n"
     ]
    }
   ],
   "source": [
    "#words_in_overview\n",
    "scalar = Normalizer()\n",
    "scalar.fit(data_tr['#words_in_overview'].values.reshape(1,-1))\n",
    "\n",
    "words_in_overview_train = scalar.transform(data_tr['#words_in_overview'].values.reshape(1,-1)).reshape(-1,1)\n",
    "words_in_overview_test = scalar.transform(data_te['#words_in_overview'].values.reshape(1,-1)).reshape(-1,1)\n",
    "\n",
    "print(words_in_overview_train.shape)\n",
    "print(words_in_overview_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 176)\n",
      "(8045, 175)\n"
     ]
    }
   ],
   "source": [
    "print(data_tr.shape)\n",
    "print(data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_tr['user_suggestion']\n",
    "data_tr.drop('user_suggestion',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25539, 175)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_tr,data_te], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>year</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Team-Based</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Local Co-Op</th>\n",
       "      <th>Turn-Based Strategy</th>\n",
       "      <th>MMORPG</th>\n",
       "      <th>...</th>\n",
       "      <th>NSFW</th>\n",
       "      <th>no_of_tags</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>preprocessed_overview</th>\n",
       "      <th>#words_in_review</th>\n",
       "      <th>#words_in_overview</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>scared hearing creepy voices pause moment writ...</td>\n",
       "      <td>survive 1000 rooms cute terror break cuteness ...</td>\n",
       "      <td>428</td>\n",
       "      <td>251</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>spooky_is_jump_scare_mansion</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>lag_studios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>best game better sam pepper youtube account 10...</td>\n",
       "      <td>survive 1000 rooms cute terror break cuteness ...</td>\n",
       "      <td>242</td>\n",
       "      <td>251</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.2516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  year            preprocessed_title    developer    publisher  \\\n",
       "0          1  2016  spooky_is_jump_scare_mansion  lag_studios  lag_studios   \n",
       "1          2  2016  spooky_is_jump_scare_mansion  lag_studios  lag_studios   \n",
       "\n",
       "   Team-Based  Sports  Local Co-Op  Turn-Based Strategy  MMORPG  ...  NSFW  \\\n",
       "0         0.0     0.0          0.0                  0.0     0.0  ...   0.0   \n",
       "1         0.0     0.0          0.0                  0.0     0.0  ...   0.0   \n",
       "\n",
       "   no_of_tags                               preprocessed_reviews  \\\n",
       "0          20  scared hearing creepy voices pause moment writ...   \n",
       "1          20  best game better sam pepper youtube account 10...   \n",
       "\n",
       "                               preprocessed_overview  #words_in_review  \\\n",
       "0  survive 1000 rooms cute terror break cuteness ...               428   \n",
       "1  survive 1000 rooms cute terror break cuteness ...               242   \n",
       "\n",
       "   #words_in_overview    neg    pos    neu  compound  \n",
       "0                 251  0.173  0.196  0.631    0.2516  \n",
       "1                 251  0.173  0.196  0.631    0.2516  \n",
       "\n",
       "[2 rows x 175 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 59)\n",
      "(8045, 59)\n"
     ]
    }
   ],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['developer'].values)\n",
    "\n",
    "developer_one_hot_train = vectorizer.transform(data_tr['developer'].values)\n",
    "developer_one_hot_test = vectorizer.transform(data_te['developer'].values)\n",
    "\n",
    "print(developer_one_hot_train.shape)\n",
    "print(developer_one_hot_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 54)\n",
      "(8045, 54)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['publisher'].values)\n",
    "\n",
    "publisher_one_hot_train = vectorizer.transform(data_tr['publisher'].values)\n",
    "publisher_one_hot_test = vectorizer.transform(data_te['publisher'].values)\n",
    "\n",
    "print(publisher_one_hot_train.shape)\n",
    "print(publisher_one_hot_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 64)\n",
      "(8045, 64)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['preprocessed_title'].values)\n",
    "\n",
    "title_one_hot_train = vectorizer.transform(data_tr['preprocessed_title'].values)\n",
    "title_one_hot_test = vectorizer.transform(data_te['preprocessed_title'].values)\n",
    "\n",
    "print(title_one_hot_train.shape)\n",
    "print(title_one_hot_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 8)\n",
      "(8045, 8)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data['year'].values)\n",
    "\n",
    "year_one_hot_train = vectorizer.transform(data_tr['year'].values)\n",
    "year_one_hot_test = vectorizer.transform(data_te['year'].values)\n",
    "\n",
    "print(year_one_hot_train.shape)\n",
    "print(year_one_hot_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (17494, 5000)\n",
      "Shape of matrix after one hot encodig  (8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf preprocessed_reviews\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer(min_df=10,ngram_range=(1,2), max_features=5000)\n",
    "vectorizer.fit(data_tr['preprocessed_reviews']) #fit\n",
    "\n",
    "reviews_bow_train = vectorizer.transform(data_tr['preprocessed_reviews']) #transform\n",
    "reviews_bow_test = vectorizer.transform(data_te['preprocessed_reviews']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",reviews_bow_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",reviews_bow_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (17494, 5000)\n",
      "Shape of matrix after one hot encodig  (8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf overview\n",
    "vectorizer = CountVectorizer(min_df=10,ngram_range=(1,2), max_features=5000)\n",
    "vectorizer.fit(data_tr['preprocessed_overview']) #fit\n",
    "\n",
    "overview_bow_train = vectorizer.transform(data_tr['preprocessed_overview']) #transform\n",
    "overview_bow_test = vectorizer.transform(data_te['preprocessed_overview']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",overview_bow_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",overview_bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (17494, 5000)\n",
      "Shape of matrix after one hot encodig  (8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf preprocessed_reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10,ngram_range=(1,2), max_features=5000)\n",
    "vectorizer.fit(data_tr['preprocessed_reviews']) #fit\n",
    "\n",
    "reviews_tfidf_train = vectorizer.transform(data_tr['preprocessed_reviews']) #transform\n",
    "reviews_tfidf_test = vectorizer.transform(data_te['preprocessed_reviews']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",reviews_tfidf_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",reviews_tfidf_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig  (17494, 5000)\n",
      "Shape of matrix after one hot encodig  (8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf overview\n",
    "vectorizer = TfidfVectorizer(min_df=10,ngram_range=(1,2), max_features=5000)\n",
    "vectorizer.fit(data_tr['preprocessed_overview']) #fit\n",
    "\n",
    "overview_tfidf_train = vectorizer.transform(data_tr['preprocessed_overview']) #transform\n",
    "overview_tfidf_test = vectorizer.transform(data_te['preprocessed_overview']) #transform\n",
    "\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",overview_tfidf_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",overview_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:38, 10298.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#loading pre-trained glove vectors\n",
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.300d.txt'), encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = embeddings_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:05<00:00, 3314.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17494\n",
      "300\n",
      "(17494, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for train(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_review_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_tr['preprocessed_reviews']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_review_train.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_review_train))\n",
    "print(len(avg_w2v_vectors_review_train[0]))\n",
    "\n",
    "avg_w2v_vectors_review_train = np.array(avg_w2v_vectors_review_train)\n",
    "print(avg_w2v_vectors_review_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:09<00:00, 1803.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17494\n",
      "300\n",
      "(17494, 300)\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for train(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_overview_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_tr['preprocessed_overview']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_overview_train.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_overview_train))\n",
    "print(len(avg_w2v_vectors_overview_train[0]))\n",
    "\n",
    "avg_w2v_vectors_overview_train = np.array(avg_w2v_vectors_overview_train)\n",
    "print(avg_w2v_vectors_overview_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:02<00:00, 3640.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8045\n",
      "300\n",
      "(8045, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for test(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_review_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_te['preprocessed_reviews']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_review_test.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_review_test))\n",
    "print(len(avg_w2v_vectors_review_test[0]))\n",
    "\n",
    "avg_w2v_vectors_review_test = np.array(avg_w2v_vectors_review_test)\n",
    "print(avg_w2v_vectors_review_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:04<00:00, 1609.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8045\n",
      "300\n",
      "(8045, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec for test(essay)\n",
    "# compute average word2vec for each review.\n",
    "avg_w2v_vectors_overview_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_te['preprocessed_overview']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += embeddings_index[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words #calculatig (w2v(word_i))/(number of words in that sentence)\n",
    "    avg_w2v_vectors_overview_test.append(vector) #stores the w2v for all sentences/reviews in the entire dataset\n",
    "\n",
    "print(len(avg_w2v_vectors_overview_test))\n",
    "print(len(avg_w2v_vectors_overview_test[0]))\n",
    "\n",
    "avg_w2v_vectors_overview_test = np.array(avg_w2v_vectors_overview_test)\n",
    "print(avg_w2v_vectors_overview_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> tfidf-w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf-w2v ESSAY\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(data_tr['preprocessed_overview'])\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [01:39<00:00, 175.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17494\n",
      "300\n",
      "(17494, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_overview_train = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_tr['preprocessed_overview']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_overview_train.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_overview_train))\n",
    "print(len(tfidf_w2v_vectors_overview_train[0]))\n",
    "\n",
    "tfidf_w2v_vectors_overview_train = np.array(tfidf_w2v_vectors_overview_train)\n",
    "print(tfidf_w2v_vectors_overview_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:32<00:00, 249.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8045\n",
      "300\n",
      "(8045, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_overview_test = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_te['preprocessed_overview']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_overview_test.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_overview_test))\n",
    "print(len(tfidf_w2v_vectors_overview_test[0]))\n",
    "\n",
    "tfidf_w2v_vectors_overview_test = np.array(tfidf_w2v_vectors_overview_test)\n",
    "print(tfidf_w2v_vectors_overview_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf-w2v ESSAY\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(data_tr['preprocessed_reviews'])\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17494/17494 [00:34<00:00, 501.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17494\n",
      "300\n",
      "(17494, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_review_train = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_tr['preprocessed_reviews']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_review_train.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_review_train))\n",
    "print(len(tfidf_w2v_vectors_review_train[0]))\n",
    "\n",
    "tfidf_w2v_vectors_review_train = np.array(tfidf_w2v_vectors_review_train)\n",
    "print(tfidf_w2v_vectors_review_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8045/8045 [00:16<00:00, 491.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8045\n",
      "300\n",
      "(8045, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_review_test = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(data_te['preprocessed_reviews']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = embeddings_index[word] # getting the vector for each word\n",
    "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
    "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_review_test.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors_review_test))\n",
    "print(len(tfidf_w2v_vectors_review_test[0]))\n",
    "\n",
    "tfidf_w2v_vectors_review_test = np.array(tfidf_w2v_vectors_review_test)\n",
    "print(tfidf_w2v_vectors_review_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Combining encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the tag columns to add in the final df\n",
    "df_tr = data_tr[tags]\n",
    "df_te = data_te[tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494, 10353)\n",
      "(8045, 10353)\n"
     ]
    }
   ],
   "source": [
    "final_train = hstack((df_tr,developer_one_hot_train,publisher_one_hot_train,title_one_hot_train,year_one_hot_train,neg_train,pos_train, neu_train,compound_train,no_of_tags_train,words_in_review_train,words_in_overview_train,reviews_tfidf_train,overview_tfidf_train))\n",
    "final_test = hstack((df_te,developer_one_hot_test,publisher_one_hot_test,title_one_hot_test,year_one_hot_test,neg_test,pos_test, neu_test,compound_test,no_of_tags_test,words_in_review_test,words_in_overview_test,reviews_tfidf_test,overview_tfidf_test))\n",
    "\n",
    "print(final_train.shape)\n",
    "print(final_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17494,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseliner(train, y, cv=3, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Function for baselining Models which return CV Score, Train Score, Valid Score\n",
    "    \"\"\"\n",
    "    print(\"Baseliner Models\\n\")\n",
    "    eval_dict = {}\n",
    "    models = [lgb.LGBMClassifier(), xgb.XGBClassifier(),  GradientBoostingClassifier(), LogisticRegression(), \n",
    "              RandomForestClassifier(), DecisionTreeClassifier(), AdaBoostClassifier(),ExtraTreeClassifier(),ExtraTreesClassifier(),\n",
    "              KNeighborsClassifier(),BaggingClassifier()\n",
    "             ]\n",
    "    print(\"Model Name \\t |   CV\")\n",
    "    print(\"--\" * 50)\n",
    "\n",
    "    for index, model in enumerate(models, 0):\n",
    "        model_name = str(model).split(\"(\")[0]\n",
    "        eval_dict[model_name] = {}\n",
    "\n",
    "        results = cross_val_score(model, train, y, cv=cv, scoring=metric)\n",
    "        eval_dict[model_name]['cv'] = results.mean()\n",
    "\n",
    "        print(\"%s \\t | %.4f \\t\" % (\n",
    "            model_name[:12], eval_dict[model_name]['cv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseliner Models\n",
      "\n",
      "Model Name \t |   CV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LGBMClassifi \t | 0.6009 \t\n",
      "XGBClassifie \t | 0.5358 \t\n",
      "GradientBoos \t | 0.5241 \t\n",
      "LogisticRegr \t | 0.6429 \t\n",
      "RandomForest \t | 0.5043 \t\n",
      "DecisionTree \t | 0.4787 \t\n",
      "AdaBoostClas \t | 0.5141 \t\n",
      "ExtraTreeCla \t | 0.4387 \t\n",
      "ExtraTreesCl \t | 0.5078 \t\n",
      "KNeighborsCl \t | 0.4819 \t\n",
      "BaggingClass \t | 0.5009 \t\n"
     ]
    }
   ],
   "source": [
    "baseliner(final_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='saga', tol=0.01, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100, class_weight=None,\n",
    "                                                dual=False, fit_intercept=True,\n",
    "                                                intercept_scaling=1,\n",
    "                                                l1_ratio=None, max_iter=200,\n",
    "                                                multi_class='warn', n_jobs=None,\n",
    "                                                penalty='l2', random_state=0,\n",
    "                                                solver='saga', tol=0.01,\n",
    "                                                verbose=0, warm_start=False)\n",
    "model.fit(final_train,Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(final_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids= data_te['review_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['review_id'] = ids\n",
    "sub['user_suggestion'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"lr_l2_01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8040</td>\n",
       "      <td>25198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8041</td>\n",
       "      <td>25199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8042</td>\n",
       "      <td>25200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8043</td>\n",
       "      <td>25201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8044</td>\n",
       "      <td>25202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8045 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_id  user_suggestion\n",
       "0          1603                0\n",
       "1          1604                0\n",
       "2          1605                0\n",
       "3          1606                0\n",
       "4          1607                1\n",
       "...         ...              ...\n",
       "8040      25198                1\n",
       "8041      25199                0\n",
       "8042      25200                0\n",
       "8043      25201                1\n",
       "8044      25202                0\n",
       "\n",
       "[8045 rows x 2 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy of 84.7% was received after submission of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
